{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eksperimen Machine Learning - Iris Dataset\n",
    "## David Dewanto\n",
    "\n",
    "Notebook ini berisi eksperimen lengkap untuk:\n",
    "1. Data Loading\n",
    "2. Exploratory Data Analysis (EDA)\n",
    "3. Data Preprocessing\n",
    "\n",
    "Dataset: Iris (Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for visualizations\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw dataset\n",
    "df_raw = pd.read_csv('../iris_raw.csv')\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df_raw.shape}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset information\n",
    "print(\"Dataset Information:\")\n",
    "print(\"=\"*50)\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"Statistical Summary:\")\n",
    "print(\"=\"*50)\n",
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Check Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "missing_values = df_raw.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(\"=\"*50)\n",
    "print(missing_values)\n",
    "print(f\"\\nTotal missing values: {missing_values.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Check Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duplicates\n",
    "duplicates = df_raw.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(\"\\nDuplicate rows:\")\n",
    "    print(df_raw[df_raw.duplicated()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution\n",
    "print(\"Species Distribution:\")\n",
    "print(\"=\"*50)\n",
    "print(df_raw['species'].value_counts())\n",
    "print(f\"\\nPercentage:\")\n",
    "print(df_raw['species'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Count plot\n",
    "df_raw['species'].value_counts().plot(kind='bar', ax=ax1, color='skyblue')\n",
    "ax1.set_title('Species Distribution (Count)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Species')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Pie chart\n",
    "df_raw['species'].value_counts().plot(kind='pie', ax=ax2, autopct='%1.1f%%')\n",
    "ax2.set_title('Species Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of numerical features\n",
    "numerical_features = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(numerical_features):\n",
    "    axes[idx].hist(df_raw[col], bins=20, color='steelblue', edgecolor='black')\n",
    "    axes[idx].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Box Plots for Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for outlier detection\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(numerical_features):\n",
    "    sns.boxplot(data=df_raw, y=col, ax=axes[idx], color='lightblue')\n",
    "    axes[idx].set_title(f'Box Plot: {col}', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "correlation_matrix = df_raw[numerical_features].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Pair Plot by Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair plot\n",
    "sns.pairplot(df_raw, hue='species', height=2.5, diag_kind='kde')\n",
    "plt.suptitle('Pair Plot of Iris Features by Species', y=1.02, fontsize=16, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Feature Statistics by Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group statistics by species\n",
    "print(\"Feature Statistics by Species:\")\n",
    "print(\"=\"*80)\n",
    "print(df_raw.groupby('species')[numerical_features].mean())\n",
    "\n",
    "print(\"\\nStandard Deviation by Species:\")\n",
    "print(\"=\"*80)\n",
    "print(df_raw.groupby('species')[numerical_features].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Create a Copy for Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "df = df_raw.copy()\n",
    "print(f\"Working with a copy of the dataset. Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Handle Missing Values (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and handle missing values\n",
    "if df.isnull().sum().sum() > 0:\n",
    "    print(\"Handling missing values...\")\n",
    "    # For numerical features, fill with median\n",
    "    for col in numerical_features:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "    print(\"Missing values handled.\")\n",
    "else:\n",
    "    print(\"No missing values found. Proceeding...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Remove Duplicates (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "before_duplicates = df.shape[0]\n",
    "df = df.drop_duplicates()\n",
    "after_duplicates = df.shape[0]\n",
    "\n",
    "print(f\"Removed {before_duplicates - after_duplicates} duplicate rows.\")\n",
    "print(f\"Dataset shape after removing duplicates: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features\n",
    "df['sepal_area'] = df['sepal length (cm)'] * df['sepal width (cm)']\n",
    "df['petal_area'] = df['petal length (cm)'] * df['petal width (cm)']\n",
    "df['sepal_ratio'] = df['sepal length (cm)'] / df['sepal width (cm)']\n",
    "df['petal_ratio'] = df['petal length (cm)'] / df['petal width (cm)']\n",
    "\n",
    "print(\"New features created:\")\n",
    "print(\"- sepal_area\")\n",
    "print(\"- petal_area\")\n",
    "print(\"- sepal_ratio\")\n",
    "print(\"- petal_ratio\")\n",
    "print(f\"\\nNew dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Label Encoding for Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding for species\n",
    "label_encoder = LabelEncoder()\n",
    "df['target_encoded'] = label_encoder.fit_transform(df['species'])\n",
    "\n",
    "print(\"Label Encoding Mapping:\")\n",
    "for idx, label in enumerate(label_encoder.classes_):\n",
    "    print(f\"{label}: {idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for scaling\n",
    "feature_columns = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', \n",
    "                   'petal width (cm)', 'sepal_area', 'petal_area', 'sepal_ratio', 'petal_ratio']\n",
    "\n",
    "# Create a scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the features\n",
    "df_scaled = df.copy()\n",
    "df_scaled[feature_columns] = scaler.fit_transform(df[feature_columns])\n",
    "\n",
    "print(\"Features scaled using StandardScaler\")\n",
    "print(\"\\nScaled features (first 5 rows):\")\n",
    "print(df_scaled[feature_columns].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare X and y\n",
    "X = df_scaled[feature_columns]\n",
    "y = df_scaled['target_encoded']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train-Test Split:\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nFeatures: {X_train.shape[1]}\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts().sort_index())\n",
    "print(f\"\\nClass distribution in testing set:\")\n",
    "print(y_test.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed dataset\n",
    "df_preprocessed = df_scaled.copy()\n",
    "df_preprocessed.to_csv('iris_preprocessing.csv', index=False)\n",
    "\n",
    "print(\"Preprocessed dataset saved to: iris_preprocessing.csv\")\n",
    "print(f\"Shape: {df_preprocessed.shape}\")\n",
    "print(\"\\nFirst few rows of preprocessed data:\")\n",
    "print(df_preprocessed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PREPROCESSING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Original dataset shape: {df_raw.shape}\")\n",
    "print(f\"Preprocessed dataset shape: {df_preprocessed.shape}\")\n",
    "print(f\"\\nOriginal features: {len(numerical_features)}\")\n",
    "print(f\"Total features after engineering: {len(feature_columns)}\")\n",
    "print(f\"New features created: {len(feature_columns) - len(numerical_features)}\")\n",
    "print(f\"\\nMissing values: {df_preprocessed.isnull().sum().sum()}\")\n",
    "print(f\"Duplicates: {df_preprocessed.duplicated().sum()}\")\n",
    "print(f\"\\nTraining samples: {X_train.shape[0]}\")\n",
    "print(f\"Testing samples: {X_test.shape[0]}\")\n",
    "print(f\"\\nTarget classes: {label_encoder.classes_.tolist()}\")\n",
    "print(\"\\nPreprocessing steps completed:\")\n",
    "print(\"✓ Data loading\")\n",
    "print(\"✓ Exploratory Data Analysis\")\n",
    "print(\"✓ Missing value handling\")\n",
    "print(\"✓ Duplicate removal\")\n",
    "print(\"✓ Feature engineering\")\n",
    "print(\"✓ Label encoding\")\n",
    "print(\"✓ Feature scaling\")\n",
    "print(\"✓ Train-test split\")\n",
    "print(\"✓ Data saved\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
